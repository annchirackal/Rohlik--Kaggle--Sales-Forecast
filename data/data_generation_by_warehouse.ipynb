{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80874,"databundleVersionId":8794587,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train.csv\")\ntest_data=pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/test.csv\")\nsolution_example=pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/solution_example.csv\")\ntest_calenders_data=pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/test_calendar.csv\")\ntrain_calenders_data=pd.read_csv(\"/kaggle/input/rohlik-orders-forecasting-challenge/train_calendar.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.dtypes,test_data.dtypes,train_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_columns=list(test_data.columns)\ntrain_columns.append(\"orders\")\ntrain_data=train_data[train_columns]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_additional_date_features(df):\n    df[\"month\"]=df.date.dt.month\n    df[\"day_num_week\"]=df.date.dt.weekday\n    df[\"year\"]=df.date.dt.year\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_outliers_iqr(df, column, threshold=1.5):\n    \"\"\"\n    Identifies outliers in a DataFrame column using the IQR method.\n\n    Parameters:\n    df (pd.DataFrame): The DataFrame containing the data.\n    column (str): The name of the column to check for outliers.\n    threshold (float): The multiplication factor for the IQR.\n\n    Returns:\n    pd.DataFrame: A DataFrame containing the outliers.\n    \"\"\"\n\n    # Calculate the IQR\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - (threshold * IQR)\n    upper_bound = Q3 + (threshold * IQR)\n\n    # Identify outliers\n    #outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n\n    return lower_bound,upper_bound ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mark_outlier(df):\n    lower_bound,upper_bound =find_outliers_iqr(df,\"orders\", threshold=1.5)\n    df_outliers = df[(df[\"orders\"] < lower_bound) | (df[\"orders\"] > upper_bound)]\n    df_non_outliers = df[(df[\"orders\"] >= lower_bound) & (df[\"orders\"] <=upper_bound)]\n    df_outliers[\"IS_OUTLIER\"]=1\n    df_non_outliers[\"IS_OUTLIER\"]=0\n    df=pd.concat([df_outliers,df_non_outliers])\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_dates(start_date, end_date):\n    \"\"\"generate all month start dates between two given dates(including the start and end date)\n    Parameters:\n              start_date(date) : starting date\n              end_date(date) : ending date\n    returns:\n      a dataframe with column name \"PERIOD\" and values all month start dates between the start and end date\n\n    \"\"\"\n\n    dates = []\n\n    date=pd.to_datetime(start_date)\n    while date<=pd.to_datetime(end_date):\n       \n        dates.append(date)\n        date = date + timedelta(days=1)\n        \n\n    df = pd.DataFrame({\"date\": dates})\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    return df\n\n\ndef add_missing_dates(df_p):\n    \"if any month start date is missing between the start and and end date identify those and add it to data frame\"\n    start_date = df_p.date.min()\n    \n    end_date = df_p.date.max()\n    \n    dates_df = generate_dates(start_date, end_date)\n    df_p[\"date\"]=pd.to_datetime(df_p[\"date\"])\n\n    df_filled = dates_df.merge(\n        df_p,\n        on=[\n            \"date\"\n        ],\n        how=\"left\",\n    )\n    df_filled[\"warehouse\"]=df_filled[\"warehouse\"].ffill()\n    df_filled[\"id\"]=df_filled[\"id\"].ffill()\n    df_filled[\"orders\"]= df_filled[\"orders\"].fillna(0)\n    return df_filled\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_data(df,warehouse):\n    df[\"date\"]=pd.to_datetime(df[\"date\"])\n    df=add_missing_dates(df)\n    df= add_additional_date_features(df)\n    encode_columns=['month','day_num_week','holiday_name']\n    if warehouse=='Munich_1':\n        transformed_train_data['orders']=(transformed_train_data['orders']\n                                          .where(transformed_train_data['day_num_week']!=6,0))\n    df=pd.get_dummies(df,columns=encode_columns)\n    df=mark_outlier(df)\n    return df\ndef transform_test_data(df,warehouse):\n    df[\"date\"]=pd.to_datetime(df[\"date\"])\n    df=add_missing_dates(df)\n    df= add_additional_date_features(df)\n    encode_columns=['month','day_num_week','holiday_name']\n    df=pd.get_dummies(df,columns=encode_columns)\n  \n    return df ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for warehouse in train_data.warehouse.unique():\n    df=train_data[train_data.warehouse==warehouse]    \n    transformed_train_data=transform_data(df,warehouse)   \n    file_name=warehouse+\"input_data.csv\"\n    transformed_train_data.to_csv(file_name)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for warehouse in train_data.warehouse.unique():\n    df=test_data[test_data.warehouse==warehouse]  \n    transformed_test_data=transform_test_data(df,warehouse)\n    file_name=warehouse+\"test_data.csv\"\n    transformed_test_data.to_csv(file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}